{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pylab import *\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sort_lidar_file_and_shape(lidar_file_name, yaml_file_name, width=2088, height=64):\n",
    "    df = pd.read_csv(lidar_file_name,\n",
    "                     names = ['x', 'y', 'z', 'intensity', 'ring', 'rotation', 'revolution'])\n",
    "    \n",
    "    yaml_file = yaml.load(open(yaml_file_name))\n",
    "    \n",
    "    calibration = yaml_file['lasers']\n",
    "    \n",
    "    sorted_lasers = sorted(calibration, key=lambda x: x['vert_correction'], reverse=True)\n",
    "\n",
    "    for i in range(0, 64):\n",
    "        df.loc[df['ring'] == i, 'rotation'] = (df.loc[df['ring'] == i, 'rotation'] \n",
    "                                               + sorted_lasers[i]['rot_correction'] * 18000 / np.pi)\n",
    "    \n",
    "    df.loc[df['rotation'] > 36000, 'rotation'] -= 36000\n",
    "    df.loc[df['rotation'] < 0, 'rotation'] += 36000\n",
    "    \n",
    "    img = np.zeros((height, width, 3))\n",
    "    for i in range(height):\n",
    "        img[i] = df.loc[df['ring'] == i].sort_values(['rotation']).as_matrix()[:, :3]\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "readings_file_name = \"1509818706.038833141-cloudpoint.csv\"\n",
    "calibration_file_name = \"64HDL_S2.yaml\"\n",
    "\n",
    "lidar_table = sort_lidar_file_and_shape(readings_file_name, calibration_file_name)\n",
    "\n",
    "width = 2088\n",
    "height = 64 \n",
    "lidar = lidar_table.reshape((width * height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dists = np.linalg.norm(lidar, axis=-1)\n",
    "#inds = np.where(dists < 10)\n",
    "\n",
    "inds = np.arange(len(lidar))\n",
    " \n",
    "lidar_center = lidar[inds]\n",
    "\n",
    "green = np.array([0, 1, 0])\n",
    "red = np.array([1, 0, 0])\n",
    "blue = np.array([0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lidar_file_name = \"lidar_test.csv\"\n",
    "\n",
    "with open(lidar_file_name, 'w') as f:\n",
    "    for rd in lidar_center:\n",
    "        f.write(\"{}, {}, {}\\n\".format(rd[0], rd[1], rd[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "order = np.zeros((height, width, 3))\n",
    "half_width = width / 2\n",
    "for i in range(width):\n",
    "    for j in range(height):\n",
    "        x = i\n",
    "#         if x >= half_width:\n",
    "#             x = width - i\n",
    "#         rgval = x / half_width\n",
    "        rgval = x / width\n",
    "        bval = j / height\n",
    "        order[j, i] = rgval * red + (1 - rgval) * green + bval * blue\n",
    "\n",
    "order = order.reshape((width * height, 3))\n",
    "\n",
    "order_center = order[inds]\n",
    "\n",
    "with open(\"width_order_colors_test.csv\", 'w') as f:\n",
    "    for rd in order_center:\n",
    "        f.write(\"{}, {}, {}\\n\".format(rd[0], rd[1], rd[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "depths = np.linalg.norm(lidar_table, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "normals = np.zeros(lidar_table.shape)\n",
    "neighbor_y_radius = 3\n",
    "\n",
    "neighbor_x_radius = 3\n",
    "\n",
    "for i in range(neighbor_y_radius, height-neighbor_y_radius - 1):\n",
    "    for j in range(0, width):        \n",
    "        neighbor_y_start = i - neighbor_y_radius\n",
    "        neighbor_y_end = i + neighbor_y_radius + 1\n",
    "        neighbor_x = np.arange(j - neighbor_x_radius, j + neighbor_x_radius + 1)\n",
    "        \n",
    "        neighbors = lidar_table[neighbor_y_start:neighbor_y_end]\n",
    "        neighbors = np.take(neighbors, neighbor_x, axis = 1, mode='wrap')\n",
    "        neighbors = neighbors.reshape(((neighbor_y_radius * 2 + 1) * (neighbor_x_radius * 2 + 1), 3))\n",
    "        \n",
    "        neighbor_depths = depths[neighbor_y_start:neighbor_y_end]\n",
    "        neighbor_depths = np.take(neighbor_depths, neighbor_x, axis=1, mode='wrap')\n",
    "        neighbor_depths = neighbor_depths.ravel()\n",
    "        \n",
    "        valid_neighbors = neighbors[np.abs(neighbor_depths - depths[i, j]) < 0.2]\n",
    "        if valid_neighbors.shape[0] >= 3:\n",
    "            covariance = np.cov(valid_neighbors, rowvar=False)\n",
    "            eigvals, eigvecs = np.linalg.eigh(covariance)\n",
    "            normals[i, j] = eigvecs[:, 0]\n",
    "            normals[i, j] /= np.linalg.norm(normals[i, j])\n",
    "            if np.dot(normals[i, j], np.array([0, 1, 0]) - \n",
    "                  lidar_table[i, j]) <= 0:\n",
    "                normals[i, j] = -normals[i, j]\n",
    "\n",
    "normal_img = normals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normal_ply_file_name = \"normals.ply\"\n",
    "normal_colors = normal_img.reshape((normal_img.shape[0] * normal_img.shape[1], 3))\n",
    "normal_points = lidar_table.reshape((lidar_table.shape[0] * lidar_table.shape[1], 3))\n",
    "with open(normal_ply_file_name, 'w') as f:\n",
    "    f.write(\"ply\\n\")\n",
    "    f.write(\"format ascii 1.0\\n\")\n",
    "    f.write(\"element vertex {}\\n\".format(len(normal_points)))\n",
    "    f.write(\"property float32 x\\n\")\n",
    "    f.write(\"property float32 y\\n\")\n",
    "    f.write(\"property float32 z\\n\")\n",
    "    f.write(\"property float32 nx\\n\")\n",
    "    f.write(\"property float32 ny\\n\")\n",
    "    f.write(\"property float32 nz\\n\")\n",
    "    f.write(\"end_header\\n\")\n",
    "    for i in range(len(normal_points)):\n",
    "        normal = normal_colors[i]\n",
    "        f.write(\"{} {} {} {} {} {}\\n\".format(normal_points[i][0], normal_points[i][1], normal_points[i][2],\n",
    "                                             normal[0], normal[1], normal[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Cluster:\n",
    "    def __init__(self, normal, num):\n",
    "        self.count = 1\n",
    "        self.normal = normal\n",
    "        self.id = num\n",
    "        self.points = set()\n",
    "        \n",
    "    def add_normal(self, normal):\n",
    "        self.normal = (self.normal * self.count + normal) / (self.count + 1)\n",
    "        self.count += 1\n",
    "        \n",
    "    def remove_normal(self, normal):\n",
    "        self.normal = (self.normal * self.count - normal) / (self.count - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/garychen/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:38: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/garychen/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:38: RuntimeWarning: invalid value encountered in arccos\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312545\n",
      "24833\n",
      "9308\n",
      "4509\n",
      "2276\n",
      "1188\n",
      "618\n",
      "319\n",
      "166\n",
      "88\n",
      "46\n",
      "24\n",
      "12\n",
      "6\n",
      "3\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "cluster_assignments = [ [Cluster(normal_img[i, j], i * normal_img.shape[1] + j) \n",
    "                         for j in range(normal_img.shape[1])]\n",
    "                       for i in range(normal_img.shape[0]) ]\n",
    "id_to_cluster = []\n",
    "for row in cluster_assignments:\n",
    "    for cluster in row:\n",
    "        id_to_cluster.append(cluster)\n",
    "\n",
    "cluster_id_to_coords = [[(i // normal_img.shape[1], i % normal_img.shape[1])]\n",
    "                        for i in range(normal_img.shape[0] * normal_img.shape[1])]\n",
    "            \n",
    "while len(to_check) > 0:\n",
    "    merges = dict()\n",
    "    remove_set = set()\n",
    "    \n",
    "    for coord in to_check:\n",
    "        x = coord[0]\n",
    "        y = coord[1]\n",
    "        \n",
    "        cluster = cluster_assignments[x][y]\n",
    "        normal = cluster.normal\n",
    "        new_cluster = None\n",
    "        \n",
    "        for dx in range(-1, 2):\n",
    "            for dy in range(-1, 2):\n",
    "                new_x = x + dx\n",
    "                if new_x >= normal_img.shape[0]:\n",
    "                    new_x -= normal_img.shape[0]\n",
    "                elif new_x < 0:\n",
    "                    new_x += normal_img.shape[0]\n",
    "                new_y = y + dy\n",
    "                \n",
    "                temp_cluster = cluster_assignments[new_x][new_y]\n",
    "                if temp_cluster.id != cluster.id:\n",
    "                    merge = (min(temp_cluster.id, cluster.id), max(temp_cluster.id, cluster.id)) \n",
    "                    \n",
    "                    angle = np.arccos(np.dot(normal, temp_cluster.normal) / \n",
    "                                      np.linalg.norm(normal) / np.linalg.norm(temp_cluster.normal))\n",
    "                    diff = np.abs(depths[new_x, new_y] - depths[x, y])\n",
    "                    \n",
    "                    if merge not in merges:\n",
    "                        if diff < 0.2 and angle < np.pi / 6:\n",
    "                            merges[merge] = angle\n",
    "                    elif diff < 0.2:\n",
    "                        merges[merge] = min(angle, merges[merge])\n",
    "                        \n",
    "    print(len(merges))\n",
    "    if len(merges) == 0:\n",
    "        break\n",
    "        \n",
    "    potential_merges = sorted(merges.keys(), key = lambda x: x[0])\n",
    "    current_cluster = potential_merges[0][0]\n",
    "    min_merge_candidate = potential_merges[0][1]\n",
    "    min_merge_angle = np.pi\n",
    "    for i in range(1, len(potential_merges) + 1):\n",
    "        if i == len(potential_merges) or potential_merges[i][0] != current_cluster:\n",
    "            coords = cluster_id_to_coords[current_cluster]\n",
    "            cluster_id_to_coords[current_cluster] = []\n",
    "            new_cluster = id_to_cluster[min_merge_candidate]\n",
    "            for coord in coords:\n",
    "                new_cluster.add_normal(normal_img[coord[0]][coord[1]])\n",
    "                cluster_assignments[coord[0]][coord[1]] = new_cluster\n",
    "            cluster_id_to_coords[min_merge_candidate] += coords\n",
    "            min_merge_angle = np.pi\n",
    "            if i < len(potential_merges) - 1:\n",
    "                min_merge_candidate = potential_merges[i + 1][1]\n",
    "                current_cluster = potential_merges[i + 1][0]\n",
    "        else:\n",
    "            if merges[potential_merges[i]] < min_merge_angle:\n",
    "                min_merge_candidate = potential_merges[i][1]\n",
    "                min_merge_angle = merges[potential_merges[i]]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-178-7734d614e60c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_lidars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mcluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_cluster_assignments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mvalid_cluster_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "valid_cluster_assignments = cluster_assignments[neighbor_y_radius:height-neighbor_y_radius - 1]\n",
    "valid_lidars = lidar_table[neighbor_y_radius:height-neighbor_y_radius - 1]\n",
    "\n",
    "# Add points to clusters\n",
    "valid_cluster_ids = set()\n",
    "for i in range(len(valid_cluster_assignments)):\n",
    "    for j in range(len(valid_cluster_assignments[i])):\n",
    "        point = valid_lidars[i, j]\n",
    "        cluster = valid_cluster_assignments[i][j]\n",
    "        cluster.points.add(point)\n",
    "        valid_cluster_ids.add(cluster.id)\n",
    "\n",
    "# Iterate through clusters and perform convex hull algorithm to get minimum bounding rectangle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "blue = np.array([0, 0, 1])\n",
    "red = np.array([1, 0, 0])\n",
    "ids = []\n",
    "\n",
    "for row in valid_cluster_assignments:\n",
    "    for cluster in row:\n",
    "        ids.append(cluster.id)\n",
    "        \n",
    "max_id = max(ids)\n",
    "colors = dict()\n",
    "\n",
    "for i in ids:\n",
    "    colors[i] = (random.random(), random.random(), random.random())\n",
    "\n",
    "with open(\"cluster_points.csv\", 'w') as f1, open(\"cluster_colors.csv\", 'w') as f2:\n",
    "    lidars = valid_lidars.reshape((valid_lidars.shape[0] * valid_lidars.shape[1], 3))\n",
    "    for i in range(len(ids)):\n",
    "        f1.write(\"{}, {}, {}\\n\".format(lidars[i][0], lidars[i][1], lidars[i][2]))\n",
    "        color = colors[ids[i]]\n",
    "        f2.write(\"{}, {}, {}\\n\".format(color[0], color[1], color[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
