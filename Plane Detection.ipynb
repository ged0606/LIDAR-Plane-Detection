{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import itertools\n",
    "from pylab import *\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Used to get nearest neighbors for surface normals\n",
    "depthXY_to_cloudXYZ = {}\n",
    "\n",
    "# Converts lidar point cloud csv to depth matrix\n",
    "\n",
    "df = pd.read_csv(\"../1504892561136210918-cloudpoint.csv\", \n",
    "                 names = ['x', 'y', 'z', 'intensity', 'ring', 'rotation', 'revolution'])\n",
    "\n",
    "df['distance'] = np.sqrt(df['x']**2 + df['y']**2 + df['z']**2)\n",
    "# np.arctan2 is element-wise arc tangent that chooses the quadrant correctly\n",
    "df['rotation-angle'] = np.arctan2(df['x'], df['y']) + np.pi\n",
    "df['inclination-angle'] = np.arctan2(df['z'], df['distance'])\n",
    "\n",
    "# img_height is number of lasers\n",
    "# img_width is number of pts/number of lasers\n",
    "img_height = 80\n",
    "img_width = 2088\n",
    "\n",
    "# calculate histogram for inclination angle\n",
    "df['inclination-angle'] = np.arctan2(df['z'], df['distance'])\n",
    "df_inclination_arr = df['inclination-angle'].as_matrix()\n",
    "hist, bin_edges = np.histogram(df_inclination_arr, bins = img_height - 1)\n",
    "\n",
    "df.sort_values(['rotation-angle'], inplace = True)\n",
    "\n",
    "bin_size = 64\n",
    "\n",
    "depth_img = np.zeros((img_width, img_height))\n",
    "\n",
    "for i in range(img_width):\n",
    "    df_rot_slice = df.iloc[bin_size * i : bin_size * (i + 1)].copy()\n",
    "    df_rot_slice_arr = df_rot_slice[['x', 'y', 'z', 'distance']]\n",
    "    pixel_bin_arr = np.digitize(df_rot_slice['inclination-angle'], bin_edges)\n",
    "\n",
    "    for j in range(len(pixel_bin_arr)):\n",
    "        pixel_vert_loc = pixel_bin_arr[j] - 1\n",
    "        depth_img[i][pixel_vert_loc] = df_rot_slice_arr['distance'].iloc[j]\n",
    "        cloudXYZ = (df_rot_slice_arr['x'].iloc[j], df_rot_slice_arr['y'].iloc[j], \n",
    "                    df_rot_slice_arr['z'].iloc[j])\n",
    "        depthXY_to_cloudXYZ[(i, pixel_vert_loc)] = cloudXYZ\n",
    "\n",
    "# Converts depth matrix to surface normal matrix\n",
    "\n",
    "# image dimensions in NumPy array,\n",
    "# 3rd dimension is for each component of normal vector\n",
    "normal_img = np.zeros((img_width, img_height, 3))\n",
    "# number of nearest point neighbors\n",
    "# i.e. radius of 1 represents a 3x3 grid of nearest pixels for the middle pixel\n",
    "nn_radius_close = 2\n",
    "nn_radius_far = 2\n",
    "# the following var are automatically set in algorithm\n",
    "nn_radius = 0\n",
    "nn_radius_for_loop = max(nn_radius_close, nn_radius_far)\n",
    "\n",
    "\n",
    "for x in range(nn_radius_for_loop, depth_img.shape[0] - nn_radius_for_loop):\n",
    "    for y in range(nn_radius_for_loop, depth_img.shape[1] - nn_radius_for_loop):\n",
    "        if not depth_img[x][y]:\n",
    "            continue\n",
    "            \n",
    "        # logic used for diff nn radius for close and far\n",
    "        if depth_img[x][y] <= 20:\n",
    "            nn_radius = nn_radius_close\n",
    "        else:\n",
    "            nn_radius = nn_radius_far\n",
    "        \n",
    "        # used to check for depth discontinuities\n",
    "        curr_depth = depth_img[x][y]\n",
    "        nn_arr = []\n",
    "        x_start = x - nn_radius\n",
    "        y_start = y - nn_radius\n",
    "        \n",
    "        # find out nearest neighbors' depths\n",
    "        for x_n in range(2 * nn_radius + 1):\n",
    "            for y_n in range(2 * nn_radius + 1):\n",
    "                x_coord = x_start + x_n\n",
    "                y_coord = y_start + y_n\n",
    "                                \n",
    "                # if there is no depth discontinuity, add it\n",
    "                if np.abs(depth_img[x_coord][y_coord] - curr_depth) < .2:\n",
    "                    if (x_coord, y_coord) in depthXY_to_cloudXYZ:\n",
    "                        cloudXYZ_value = depthXY_to_cloudXYZ[(x_coord, y_coord)]\n",
    "                        nn_arr.append(cloudXYZ_value)\n",
    "        \n",
    "        # can only do PCA if more than one nearest neighbor\n",
    "        if (len(nn_arr) <= 1):\n",
    "            continue\n",
    "        nn_matrix = np.array(nn_arr)\n",
    "               \n",
    "        # mean center the data\n",
    "        nn_matrix -= np.mean(nn_matrix, axis=0)\n",
    "        # calculate the covariance matrix\n",
    "        cov_matrix = np.cov(nn_matrix, rowvar=False)\n",
    "        # calculate eigenvectors & eigenvalues of the covariance matrix\n",
    "        # use 'eigh' rather than 'eig' since R is symmetric, \n",
    "        # the performance gain is substantial\n",
    "        # eigenvectors are in increasing order of eigenvalue\n",
    "        eigvals, eigvecs = np.linalg.eigh(cov_matrix)\n",
    "        # sort eigenvectors in decreasing order\n",
    "        # eigvecs = np.flip(eigvecs, axis=1)\n",
    "        \n",
    "        # the eigenvector corresponding to the smallest eigenvalue\n",
    "        # represents the surface normal of the regression plane\n",
    "        normal = eigvecs[:,0]\n",
    "        \n",
    "        # if surface normal is in the wrong direction, flip it!\n",
    "        if np.dot(normal, np.array([0, 0, 0]) - \n",
    "                  np.array(list(depthXY_to_cloudXYZ[(x, y)]))) <= 0:\n",
    "            normal = -normal\n",
    "        \n",
    "        normal_img[x][y][0] = normal[0]\n",
    "        normal_img[x][y][1] = normal[1]\n",
    "        normal_img[x][y][2] = normal[2] \n",
    "\n",
    "# Interpolation\n",
    "\n",
    "mapping = {}\n",
    "# number of nearest point neighbors\n",
    "# i.e. radius of 1 represents a 3x3 grid of nearest pixels for the middle pixel\n",
    "nn_radius = 1\n",
    "\n",
    "for x in range(nn_radius, normal_img.shape[0] - nn_radius):\n",
    "    for y in range(nn_radius, normal_img.shape[1] - nn_radius):\n",
    "        # skip if not an empty pixel\n",
    "        if normal_img[x][y][0] or normal_img[x][y][1] or normal_img[x][y][2]:\n",
    "            continue\n",
    "\n",
    "        nn_arr = []\n",
    "        x_start = x - nn_radius\n",
    "        y_start = y - nn_radius\n",
    "\n",
    "        # find out nearest neighbors' surface normal vectors\n",
    "        for x_n in range(2 * nn_radius + 1):\n",
    "            for y_n in range(2 * nn_radius + 1):\n",
    "                pixel = normal_img[x_start + x_n][y_start + y_n]\n",
    "                if pixel[0] or pixel[1] or pixel[2]:\n",
    "                    nn_arr.append(pixel)\n",
    "\n",
    "        # skip sky\n",
    "        if (x < img_height/3):\n",
    "            if (len(nn_arr) <= 2):\n",
    "                continue\n",
    "        else:\n",
    "            if (len(nn_arr) <= 0):\n",
    "                continue\n",
    "        \n",
    "        nn_matrix = np.array(nn_arr)\n",
    "\n",
    "        # fill empty pixel with average of filled in neighbors\n",
    "        nn_avg = np.mean(nn_matrix, axis=0)\n",
    "        mapping[(x, y)] = nn_avg\n",
    "        \n",
    "for x, y in mapping: \n",
    "    normal_img[x][y][0] = mapping[(x, y)][0]\n",
    "    normal_img[x][y][1] = mapping[(x, y)][1]\n",
    "    normal_img[x][y][2] = mapping[(x, y)][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_table = np.zeros(normal_img.shape)\n",
    "for key in depthXY_to_cloudXYZ:\n",
    "    point = depthXY_to_cloudXYZ[key]\n",
    "    if key[1] < lidar_table.shape[1] and key[0] < lidar_table.shape[0]:\n",
    "        lidar_table[key[0], key[1]] = point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normal_ply_file_name = \"normals.ply\"\n",
    "normal_colors = normal_img.reshape((normal_img.shape[0] * normal_img.shape[1], 3))\n",
    "normal_points = lidar_table.reshape((lidar_table.shape[0] * lidar_table.shape[1], 3))\n",
    "with open(normal_ply_file_name, 'w') as f:\n",
    "    f.write(\"ply\\n\")\n",
    "    f.write(\"format ascii 1.0\\n\")\n",
    "    f.write(\"element vertex {}\\n\".format(len(normal_points)))\n",
    "    f.write(\"property float32 x\\n\")\n",
    "    f.write(\"property float32 y\\n\")\n",
    "    f.write(\"property float32 z\\n\")\n",
    "    f.write(\"property float32 nx\\n\")\n",
    "    f.write(\"property float32 ny\\n\")\n",
    "    f.write(\"property float32 nz\\n\")\n",
    "    f.write(\"end_header\\n\")\n",
    "    for i in range(len(normal_points)):\n",
    "        normal = normal_colors[i]\n",
    "        f.write(\"{} {} {} {} {} {}\\n\".format(normal_points[i][0], normal_points[i][1], normal_points[i][2],\n",
    "                                             normal[0], normal[1], normal[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Cluster:\n",
    "    def __init__(self, normal, num):\n",
    "        self.count = 1\n",
    "        self.normal = normal\n",
    "        self.id = num\n",
    "        \n",
    "    def add_normal(self, normal):\n",
    "        self.normal = (self.normal * self.count + normal) / (self.count + 1)\n",
    "        self.count += 1\n",
    "        \n",
    "    def remove_normal(self, normal):\n",
    "        self.normal = (self.normal * self.count - normal) / (self.count - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/garychen/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:45: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/garychen/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:45: RuntimeWarning: invalid value encountered in arccos\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307046\n",
      "25642\n",
      "12027\n",
      "6038\n",
      "3086\n",
      "1584\n",
      "826\n",
      "447\n",
      "236\n",
      "127\n",
      "62\n",
      "31\n",
      "15\n",
      "10\n",
      "8\n",
      "5\n",
      "2\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "cluster_assignments = [ [Cluster(normal_img[i, j], i * normal_img.shape[1] + j) \n",
    "                         for j in range(normal_img.shape[1])]\n",
    "                       for i in range(normal_img.shape[0]) ]\n",
    "id_to_cluster = []\n",
    "for row in cluster_assignments:\n",
    "    for cluster in row:\n",
    "        id_to_cluster.append(cluster)\n",
    "\n",
    "cluster_id_to_coords = [[(i // normal_img.shape[1], i % normal_img.shape[1])]\n",
    "                        for i in range(normal_img.shape[0] * normal_img.shape[1])]\n",
    "\n",
    "to_check = set()\n",
    "for i in range(normal_img.shape[0]):\n",
    "    for j in range(1, normal_img.shape[1] - 1):\n",
    "        if not np.array_equal(normal_img[i, j], np.array([0, 0, 0])):\n",
    "            to_check.add((i, j))\n",
    "            \n",
    "while len(to_check) > 0:\n",
    "    merges = dict()\n",
    "    remove_set = set()\n",
    "    \n",
    "    for coord in to_check:\n",
    "        x = coord[0]\n",
    "        y = coord[1]\n",
    "        \n",
    "        cluster = cluster_assignments[x][y]\n",
    "        normal = cluster.normal\n",
    "        new_cluster = None\n",
    "        \n",
    "        should_remove = True\n",
    "        for dx in range(-1, 2):\n",
    "            for dy in range(-1, 2):\n",
    "                new_x = x + dx\n",
    "                if new_x >= normal_img.shape[0]:\n",
    "                    new_x -= normal_img.shape[0]\n",
    "                elif new_x < 0:\n",
    "                    new_x += normal_img.shape[0]\n",
    "                new_y = y + dy\n",
    "                \n",
    "                temp_cluster = cluster_assignments[new_x][new_y]\n",
    "                if temp_cluster.id != cluster.id:\n",
    "                    merge = (min(temp_cluster.id, cluster.id), max(temp_cluster.id, cluster.id)) \n",
    "                    if merge not in merges:\n",
    "                        angle = np.arccos(np.dot(normal, temp_cluster.normal) / \n",
    "                                          np.linalg.norm(normal) / np.linalg.norm(temp_cluster.normal))\n",
    "                        diff = lidar_table[new_x, new_y] - lidar_table[x, y]\n",
    "                        dist = np.dot(diff, diff)\n",
    "                        if angle < np.pi / 6 and dist < 1.0:\n",
    "                            should_remove = False\n",
    "                            merges[merge] = angle\n",
    "        \n",
    "#         if should_remove:\n",
    "#             remove_set.add(coord)\n",
    "    print(len(merges))\n",
    "    if len(merges) == 0:\n",
    "        break\n",
    "        \n",
    "    potential_merges = sorted(merges.keys(), key = lambda x: x[0])\n",
    "    current_cluster = potential_merges[0][0]\n",
    "    min_merge_candidate = potential_merges[0][1]\n",
    "    min_merge_angle = np.pi\n",
    "    for i in range(1, len(potential_merges) + 1):\n",
    "        if i == len(potential_merges) or potential_merges[i][0] != current_cluster:\n",
    "            coords = cluster_id_to_coords[current_cluster]\n",
    "            cluster_id_to_coords[current_cluster] = []\n",
    "            new_cluster = id_to_cluster[min_merge_candidate]\n",
    "            for coord in coords:\n",
    "                new_cluster.add_normal(normal_img[coord[0]][coord[1]])\n",
    "                cluster_assignments[coord[0]][coord[1]] = new_cluster\n",
    "            cluster_id_to_coords[min_merge_candidate] += coords\n",
    "            min_merge_angle = np.pi\n",
    "            if i < len(potential_merges) - 1:\n",
    "                min_merge_candidate = potential_merges[i + 1][1]\n",
    "                current_cluster = potential_merges[i + 1][0]\n",
    "        else:\n",
    "            if merges[potential_merges[i]] < min_merge_angle:\n",
    "                min_merge_candidate = potential_merges[i][1]\n",
    "                min_merge_angle = merges[potential_merges[i]]\n",
    "            \n",
    "#     to_check = to_check.difference(remove_set)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "blue = np.array([0, 0, 1])\n",
    "red = np.array([1, 0, 0])\n",
    "ids = []\n",
    "for row in cluster_assignments:\n",
    "    for cluster in row:\n",
    "        ids.append(cluster.id)\n",
    "max_id = max(ids)\n",
    "colors = [(random.random(), random.random(), random.random())for i in ids]\n",
    "with open(\"cluster_points.csv\", 'w') as f1, open(\"cluster_colors.csv\", 'w') as f2:\n",
    "    lidars = lidar_table.reshape((lidar_table.shape[0] * lidar_table.shape[1], 3))\n",
    "    \n",
    "    for i in range(len(ids)):\n",
    "        f1.write(\"{}, {}, {}\\n\".format(lidars[i][0], lidars[i][1], lidars[i][2]))\n",
    "        color = colors[ids[i]]\n",
    "        f2.write(\"{}, {}, {}\\n\".format(color[0], color[1], color[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
